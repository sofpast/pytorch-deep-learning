{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_pytorch_computer_vision_exercises.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sofpast/pytorch-deep-learning/blob/main/extras/exercises/03_pytorch_computer_vision_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 03. PyTorch Computer Vision Exercises\n",
        "\n",
        "The following is a collection of exercises based on computer vision fundamentals in PyTorch.\n",
        "\n",
        "They're a bunch of fun.\n",
        "\n",
        "You're going to get to write plenty of code!\n",
        "\n",
        "## Resources\n",
        "\n",
        "1. These exercises are based on [notebook 03 of the Learn PyTorch for Deep Learning course](https://www.learnpytorch.io/03_pytorch_computer_vision/).\n",
        "2. See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/_PibmqpEyhA).\n",
        "  * **Note:** Going through these exercises took me just over 3 hours of solid coding, so you should expect around the same.\n",
        "3. See [other solutions on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions)."
      ],
      "metadata": {
        "id": "Vex99np2wFVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaeYzOTLwWh2",
        "outputId": "7507429a-f77b-46a8-c532-0156a33c6015"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import torch\n",
        "import torch\n",
        "\n",
        "# Exercises require PyTorch > 1.10.0\n",
        "print(torch.__version__)\n",
        "\n",
        "# TODO: Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() is True else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "DNwZLMbCzJLk",
        "outputId": "c9ca3c25-3fc8-43af-85f5-ae8349a9ca33"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu118\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. What are 3 areas in industry where computer vision is currently being used?"
      ],
      "metadata": {
        "id": "FSFX7tc1w-en"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# camera apps, modern cars, and manufacturers"
      ],
      "metadata": {
        "id": "VyWRkvWGbCXj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find."
      ],
      "metadata": {
        "id": "oBK-WI6YxDYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Overfitting means our model is learning the training data well but those patterns aren't generalizing to the testing data."
      ],
      "metadata": {
        "id": "d1rxD6GObCqh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each.\n",
        "> **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those."
      ],
      "metadata": {
        "id": "XeYFEqw8xK26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Two of main to fix overfitting include:\n",
        "# 1. Using a smaller or different model\n",
        "# 2. Using a larger dataset"
      ],
      "metadata": {
        "id": "ocvOdWKcbEKr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
        "\n",
        "* Upload your own example image using the \"upload\" button on the website and see what happens in each layer of a CNN as your image passes through it."
      ],
      "metadata": {
        "id": "DKdEEFEqxM-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "m = nn.Softmax(dim=1)\n",
        "input = torch.randn(1, 4)\n",
        "print(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dre_6KzaNKdc",
        "outputId": "38a20554-bc56-4532-c28c-d9e5f89403cf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5161, 1.7055, 0.9420, 0.9916]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = m(input)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qb27-AvOCiZ",
        "outputId": "1602122e-3471-4b13-e6af-06ab19f90bce"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1347, 0.4424, 0.2062, 0.2167]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets."
      ],
      "metadata": {
        "id": "lvf-3pODxXYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Import torchvision\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Import matplotlib for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check version\n",
        "print(f\"PyTorch version: {torch.__version__}\\ntorchvision: {torchvision.__version__}\")\n"
      ],
      "metadata": {
        "id": "SHjeuN81bHza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07922020-1f93-4259-84eb-f8dc6f3a796e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.1.0+cu118\n",
            "torchvision: 0.16.0+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "# Testing data\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKIJCjnTVgJv",
        "outputId": "88cead9f-b66b-4755-8ca1-b3835de2cc81"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 19193016.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 301490.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5567516.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 6070361.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[0]\n",
        "image, label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LWEfOxfWHH3",
        "outputId": "767965ce-103b-47b0-e17e-6ce78b7e5935"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
              "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
              "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
              "           0.0157, 0.0000, 0.0000, 0.0118],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
              "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0471, 0.0392, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
              "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
              "           0.3020, 0.5098, 0.2824, 0.0588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
              "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
              "           0.5529, 0.3451, 0.6745, 0.2588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
              "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
              "           0.4824, 0.7686, 0.8980, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
              "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
              "           0.8745, 0.9608, 0.6784, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
              "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
              "           0.8627, 0.9529, 0.7922, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
              "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
              "           0.8863, 0.7725, 0.8196, 0.2039],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
              "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
              "           0.9608, 0.4667, 0.6549, 0.2196],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
              "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
              "           0.8510, 0.8196, 0.3608, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
              "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
              "           0.8549, 1.0000, 0.3020, 0.0000],\n",
              "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
              "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
              "           0.8784, 0.9569, 0.6235, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
              "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
              "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
              "           0.9137, 0.9333, 0.8431, 0.0000],\n",
              "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
              "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
              "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
              "           0.8627, 0.9098, 0.9647, 0.0000],\n",
              "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
              "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
              "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
              "           0.8706, 0.8941, 0.8824, 0.0000],\n",
              "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
              "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
              "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
              "           0.8745, 0.8784, 0.8980, 0.1137],\n",
              "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
              "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
              "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
              "           0.8627, 0.8667, 0.9020, 0.2627],\n",
              "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
              "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
              "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
              "           0.7098, 0.8039, 0.8078, 0.4510],\n",
              "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
              "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
              "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
              "           0.6549, 0.6941, 0.8235, 0.3608],\n",
              "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
              "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
              "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
              "           0.7529, 0.8471, 0.6667, 0.0000],\n",
              "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
              "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
              "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
              "           0.3882, 0.2275, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
              "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
              " 9)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(image.shape)\n",
        "print(len(train_data.data), len(train_data.targets), len(test_data.data), len(test_data.targets))\n",
        "class_names = train_data.classes\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hHucO4FWP3z",
        "outputId": "1b6a8894-bb05-44e8-f4c9-f287983e7e19"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "60000 60000 10000 10000\n",
            "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Visualize at least 5 different samples of the MNIST training dataset."
      ],
      "metadata": {
        "id": "qxZW-uAbxe_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot image\n",
        "torch.manual_seed(23)\n",
        "fig = plt.figure(figsize=(9, 9))\n",
        "rows, cols = 4, 4\n",
        "for i in range(1, rows * cols + 1):\n",
        "  random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
        "  img, label = train_data[random_idx]\n",
        "  fig.add_subplot(rows, cols, i)\n",
        "  plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "  plt.title(class_names[label])\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "QVFsYi1PbItE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "outputId": "39ceebad-24c0-46b6-d786-7274d1420ac3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x900 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`."
      ],
      "metadata": {
        "id": "JAPDzW0wxhi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Turn datasets into iterables (batches)\n",
        "train_dataloader = DataLoader(\n",
        "    train_data,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_data,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = False\n",
        ")\n",
        "\n",
        "print(f\"Dataloaders: {train_dataloader, test_dataloader}\")\n",
        "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
        "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")\n"
      ],
      "metadata": {
        "id": "ALA6MPcFbJXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d497577-efc2-4ab0-e350-940a7445b132"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x7c3318e5f1c0>, <torch.utils.data.dataloader.DataLoader object at 0x7c3318e5eb00>)\n",
            "Length of train dataloader: 1875 batches of 32\n",
            "Length of test dataloader: 313 batches of 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Recreate `model_2` used in notebook 03 (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset."
      ],
      "metadata": {
        "id": "bCCVfXk5xjYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionMNISTModelV2(nn.Module):\n",
        "  def __init__(self, input_shape: int, output_shape: int, hidden_units: int):\n",
        "    super().__init__()\n",
        "    self.block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(\n",
        "            kernel_size=2,\n",
        "            stride=2\n",
        "        )\n",
        "    )\n",
        "    self.block_2 = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels=hidden_units,\n",
        "            out_channels=hidden_units,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1\n",
        "        ),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(\n",
        "            kernel_size=2\n",
        "        )\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(\n",
        "            in_features=hidden_units*7*7,\n",
        "            out_features=output_shape\n",
        "        )\n",
        "    )\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    x = self.block_1(x)\n",
        "    x = self.block_2(x)\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model_2 = FashionMNISTModelV2(input_shape=1,\n",
        "                              hidden_units=10,\n",
        "                              output_shape=len(class_names)).to(device)\n",
        "model_2\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5IKNF22XbKYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b6637ab-dddd-4d52-c578-1e5e650a6909"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FashionMNISTModelV2(\n",
              "  (block_1): Sequential(\n",
              "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block_2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Train the model you built in exercise 8. for 5 epochs on CPU and GPU and see how long it takes on each."
      ],
      "metadata": {
        "id": "sf_3zUr7xlhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_2.parameters(),\n",
        "                            lr=0.1)"
      ],
      "metadata": {
        "id": "jSo6vVWFbNLD"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper_functions.py already exists, skipping download\")\n",
        "else:\n",
        "  print(\"Downloading helper_functions.py\")\n",
        "  # Note: you need the \"raw\" GitHub URL for this to work\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)\n",
        "# Import accuracy metric\n",
        "from helper_functions import accuracy_fn"
      ],
      "metadata": {
        "id": "HFsbjHEvWf4D",
        "outputId": "97096c58-866c-4ed2-ddb4-191d9cfe56fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "helper_functions.py already exists, skipping download\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_step\n",
        "def train_step(\n",
        "    model: torch.nn.Module,\n",
        "    data_loader: torch.utils.data.DataLoader,\n",
        "    loss_fn: torch.nn.Module,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    accuracy_fn,\n",
        "    device: torch.device = device):\n",
        "\n",
        "  train_loss, train_acc = 0, 0\n",
        "  model.to(device)\n",
        "\n",
        "  for batch, (X, y) in enumerate(data_loader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    y_pred = model(X)\n",
        "\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss\n",
        "    train_acc += accuracy_fn(y_true=y,\n",
        "                            y_pred = y_pred.argmax(dim=1))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  train_loss /= len(data_loader)\n",
        "  train_acc /= len(data_loader)\n",
        "  print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.5f}%\")\n",
        "\n",
        "def test_step(data_loader: torch.utils.data.DataLoader,\n",
        "              model: torch.nn.Module,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              accuracy_fn,\n",
        "              device: torch.device = device):\n",
        "  test_loss, test_acc = 0, 0\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for X, y in data_loader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      test_pred = model(X)\n",
        "\n",
        "      test_loss += loss_fn(test_pred, y)\n",
        "      test_acc += accuracy_fn(y_true=y,\n",
        "                              y_pred=test_pred.argmax(dim=1)\n",
        "                              )\n",
        "      test_loss /= len(data_loader)\n",
        "      test_acc /= len(data_loader)\n",
        "      print(f\"Test loss: {test_loss:.5f} | Test Accuracy: {test_acc:.5f} %\")\n",
        "\n"
      ],
      "metadata": {
        "id": "n6AJHH9VR5VT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training model\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "from tqdm import tqdm\n",
        "start_time = timer()\n",
        "epochs = 5\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n------------\")\n",
        "  train_step(data_loader=train_dataloader,\n",
        "            model=model_2,\n",
        "            loss_fn=loss_fn,\n",
        "            optimizer=optimizer,\n",
        "            accuracy_fn=accuracy_fn\n",
        "             )\n",
        "  test_step(\n",
        "      data_loader=test_dataloader,\n",
        "      model=model_2,\n",
        "      loss_fn=loss_fn,\n",
        "      accuracy_fn=accuracy_fn\n",
        "  )\n",
        "\n",
        "end_time = timer()\n",
        "\n",
        "print(f\"Training time: {end_time - start_time}\")"
      ],
      "metadata": {
        "id": "UDV1oYybVCBS",
        "outputId": "46eebacd-c8c3-4c3b-cb1f-c5c0efa56427",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "------------\n",
            "Train loss: 0.59518 | Train accuracy: 78.37500%\n",
            "Test loss: 0.00157 | Test Accuracy: 0.25958 %\n",
            "Test loss: 0.00154 | Test Accuracy: 0.25043 %\n",
            "Test loss: 0.00117 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00061 | Test Accuracy: 0.32038 %\n",
            "Test loss: 0.00131 | Test Accuracy: 0.28058 %\n",
            "Test loss: 0.00057 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00142 | Test Accuracy: 0.24061 %\n",
            "Test loss: 0.00068 | Test Accuracy: 0.32026 %\n",
            "Test loss: 0.00095 | Test Accuracy: 0.27059 %\n",
            "Test loss: 0.00112 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00139 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00165 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00160 | Test Accuracy: 0.23059 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.28029 %\n",
            "Test loss: 0.00192 | Test Accuracy: 0.25050 %\n",
            "Test loss: 0.00112 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00150 | Test Accuracy: 0.28039 %\n",
            "Test loss: 0.00147 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00123 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00113 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00128 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00247 | Test Accuracy: 0.22054 %\n",
            "Test loss: 0.00156 | Test Accuracy: 0.27027 %\n",
            "Test loss: 0.00110 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00168 | Test Accuracy: 0.25043 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00122 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00164 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00138 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00127 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00123 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00144 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00101 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00127 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00225 | Test Accuracy: 0.24048 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.30029 %\n",
            "Test loss: 0.00113 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00181 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.31034 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.27056 %\n",
            "Test loss: 0.00167 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00073 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00155 | Test Accuracy: 0.25050 %\n",
            "Test loss: 0.00190 | Test Accuracy: 0.25040 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00199 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00110 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00152 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00044 | Test Accuracy: 0.32035 %\n",
            "Test loss: 0.00065 | Test Accuracy: 0.31053 %\n",
            "Test loss: 0.00156 | Test Accuracy: 0.25059 %\n",
            "Test loss: 0.00174 | Test Accuracy: 0.26039 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00122 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00131 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00154 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00151 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.28038 %\n",
            "Test loss: 0.00203 | Test Accuracy: 0.25050 %\n",
            "Test loss: 0.00158 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00135 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00096 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00180 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00140 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00236 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00191 | Test Accuracy: 0.24045 %\n",
            "Test loss: 0.00170 | Test Accuracy: 0.28032 %\n",
            "Test loss: 0.00121 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00118 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00145 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00043 | Test Accuracy: 0.32038 %\n",
            "Test loss: 0.00180 | Test Accuracy: 0.25062 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.26039 %\n",
            "Test loss: 0.00265 | Test Accuracy: 0.22048 %\n",
            "Test loss: 0.00184 | Test Accuracy: 0.25031 %\n",
            "Test loss: 0.00173 | Test Accuracy: 0.24042 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.27034 %\n",
            "Test loss: 0.00063 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00085 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00131 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00261 | Test Accuracy: 0.23046 %\n",
            "Test loss: 0.00154 | Test Accuracy: 0.27030 %\n",
            "Test loss: 0.00158 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00113 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00144 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00082 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00145 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00125 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00145 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00119 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00142 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00155 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00182 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00180 | Test Accuracy: 0.24045 %\n",
            "Test loss: 0.00156 | Test Accuracy: 0.25037 %\n",
            "Test loss: 0.00241 | Test Accuracy: 0.25040 %\n",
            "Test loss: 0.00108 | Test Accuracy: 0.25040 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.30032 %\n",
            "Test loss: 0.00186 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00106 | Test Accuracy: 0.28039 %\n",
            "Test loss: 0.00095 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00048 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00142 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00230 | Test Accuracy: 0.23043 %\n",
            "Test loss: 0.00087 | Test Accuracy: 0.30026 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00075 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00232 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00160 | Test Accuracy: 0.24042 %\n",
            "Test loss: 0.00143 | Test Accuracy: 0.27034 %\n",
            "Test loss: 0.00152 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00127 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00179 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00150 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00163 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00149 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00134 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00144 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00209 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00194 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00049 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00084 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00180 | Test Accuracy: 0.24051 %\n",
            "Test loss: 0.00157 | Test Accuracy: 0.28032 %\n",
            "Test loss: 0.00308 | Test Accuracy: 0.23053 %\n",
            "Test loss: 0.00077 | Test Accuracy: 0.29027 %\n",
            "Test loss: 0.00300 | Test Accuracy: 0.20061 %\n",
            "Test loss: 0.00119 | Test Accuracy: 0.29018 %\n",
            "Test loss: 0.00130 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00123 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00183 | Test Accuracy: 0.24045 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.29030 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00195 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.28039 %\n",
            "Test loss: 0.00033 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00101 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00167 | Test Accuracy: 0.23056 %\n",
            "Test loss: 0.00122 | Test Accuracy: 0.29027 %\n",
            "Test loss: 0.00194 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00060 | Test Accuracy: 0.30032 %\n",
            "Test loss: 0.00150 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00122 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00145 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00086 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00122 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00205 | Test Accuracy: 0.25046 %\n",
            "Test loss: 0.00131 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00119 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00127 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00148 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00119 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00164 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00209 | Test Accuracy: 0.25043 %\n",
            "Test loss: 0.00152 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00125 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00171 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00162 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00072 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00106 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00113 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00154 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00135 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00127 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00143 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00068 | Test Accuracy: 0.30032 %\n",
            "Test loss: 0.00142 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00105 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00129 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00106 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00160 | Test Accuracy: 0.24048 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.28032 %\n",
            "Test loss: 0.00082 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00130 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00029 | Test Accuracy: 0.32042 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.29056 %\n",
            "Test loss: 0.00112 | Test Accuracy: 0.29047 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00133 | Test Accuracy: 0.25050 %\n",
            "Test loss: 0.00151 | Test Accuracy: 0.26038 %\n",
            "Test loss: 0.00147 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.31034 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00159 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.25046 %\n",
            "Test loss: 0.00144 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00103 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00150 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00134 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00134 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00144 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00162 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00060 | Test Accuracy: 0.30032 %\n",
            "Test loss: 0.00151 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00145 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00128 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00086 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00096 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00085 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00121 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00184 | Test Accuracy: 0.24054 %\n",
            "Test loss: 0.00150 | Test Accuracy: 0.27034 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00211 | Test Accuracy: 0.21059 %\n",
            "Test loss: 0.00282 | Test Accuracy: 0.21034 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.28022 %\n",
            "Test loss: 0.00093 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00148 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00178 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00129 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00087 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00163 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00101 | Test Accuracy: 0.28038 %\n",
            "Test loss: 0.00162 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00204 | Test Accuracy: 0.23046 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.29027 %\n",
            "Test loss: 0.00149 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00160 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00122 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00122 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00177 | Test Accuracy: 0.23053 %\n",
            "Test loss: 0.00100 | Test Accuracy: 0.28029 %\n",
            "Test loss: 0.00048 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00128 | Test Accuracy: 0.27056 %\n",
            "Test loss: 0.00198 | Test Accuracy: 0.25047 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.26038 %\n",
            "Test loss: 0.00153 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00180 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00117 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00153 | Test Accuracy: 0.23056 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.29027 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.30039 %\n",
            "Test loss: 0.00049 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00153 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.28042 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 1/5 [00:57<03:49, 57.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.00124 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00166 | Test Accuracy: 0.24051 %\n",
            "Test loss: 0.00108 | Test Accuracy: 0.30029 %\n",
            "Epoch: 1\n",
            "------------\n",
            "Train loss: 0.36536 | Train accuracy: 86.90167%\n",
            "Test loss: 0.00157 | Test Accuracy: 0.27955 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00065 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00139 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00043 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00073 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00135 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00046 | Test Accuracy: 0.32029 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.27059 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00086 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00145 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00129 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00172 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00087 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00151 | Test Accuracy: 0.24058 %\n",
            "Test loss: 0.00158 | Test Accuracy: 0.28032 %\n",
            "Test loss: 0.00123 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00139 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00085 | Test Accuracy: 0.28038 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00100 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.28038 %\n",
            "Test loss: 0.00241 | Test Accuracy: 0.23053 %\n",
            "Test loss: 0.00164 | Test Accuracy: 0.27031 %\n",
            "Test loss: 0.00086 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00073 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00169 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00174 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.28038 %\n",
            "Test loss: 0.00121 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00095 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00142 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00131 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00132 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00050 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00209 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00054 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00095 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00167 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00074 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00122 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00132 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00231 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00138 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00040 | Test Accuracy: 0.32045 %\n",
            "Test loss: 0.00064 | Test Accuracy: 0.28058 %\n",
            "Test loss: 0.00106 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00046 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00049 | Test Accuracy: 0.32048 %\n",
            "Test loss: 0.00148 | Test Accuracy: 0.24064 %\n",
            "Test loss: 0.00158 | Test Accuracy: 0.25037 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00073 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00084 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00164 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00158 | Test Accuracy: 0.25046 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00178 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00167 | Test Accuracy: 0.25040 %\n",
            "Test loss: 0.00087 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00096 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00060 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00181 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00133 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00207 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00198 | Test Accuracy: 0.25043 %\n",
            "Test loss: 0.00160 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00117 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00144 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00121 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00038 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00167 | Test Accuracy: 0.25059 %\n",
            "Test loss: 0.00122 | Test Accuracy: 0.26039 %\n",
            "Test loss: 0.00207 | Test Accuracy: 0.23046 %\n",
            "Test loss: 0.00182 | Test Accuracy: 0.25034 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00064 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00072 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00220 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00117 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00173 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00101 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00121 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00132 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00118 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00129 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00105 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00154 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00079 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00130 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00143 | Test Accuracy: 0.25043 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00193 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00139 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00218 | Test Accuracy: 0.24048 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.29031 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00177 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00095 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00031 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00053 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00056 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00101 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00113 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00061 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00150 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00199 | Test Accuracy: 0.24051 %\n",
            "Test loss: 0.00087 | Test Accuracy: 0.28032 %\n",
            "Test loss: 0.00105 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00057 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00223 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00129 | Test Accuracy: 0.26039 %\n",
            "Test loss: 0.00129 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00146 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00054 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00191 | Test Accuracy: 0.26058 %\n",
            "Test loss: 0.00160 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00187 | Test Accuracy: 0.24045 %\n",
            "Test loss: 0.00096 | Test Accuracy: 0.28032 %\n",
            "Test loss: 0.00155 | Test Accuracy: 0.24051 %\n",
            "Test loss: 0.00131 | Test Accuracy: 0.28032 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00190 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00220 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00035 | Test Accuracy: 0.32035 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.30054 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00189 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00122 | Test Accuracy: 0.25040 %\n",
            "Test loss: 0.00304 | Test Accuracy: 0.23043 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.28029 %\n",
            "Test loss: 0.00292 | Test Accuracy: 0.23053 %\n",
            "Test loss: 0.00118 | Test Accuracy: 0.27031 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00149 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00046 | Test Accuracy: 0.32035 %\n",
            "Test loss: 0.00149 | Test Accuracy: 0.26061 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00028 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00082 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.25046 %\n",
            "Test loss: 0.00131 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00167 | Test Accuracy: 0.25046 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00100 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00056 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00063 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00145 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00135 | Test Accuracy: 0.28039 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00146 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00119 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00125 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00154 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00155 | Test Accuracy: 0.25043 %\n",
            "Test loss: 0.00140 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00139 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00130 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00134 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00056 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00110 | Test Accuracy: 0.27056 %\n",
            "Test loss: 0.00103 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00117 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.28038 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00108 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00137 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00084 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00074 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00038 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00087 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.25050 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00055 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00068 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00074 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00101 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00145 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00125 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00093 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00140 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00122 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00037 | Test Accuracy: 0.32035 %\n",
            "Test loss: 0.00156 | Test Accuracy: 0.26061 %\n",
            "Test loss: 0.00065 | Test Accuracy: 0.31034 %\n",
            "Test loss: 0.00133 | Test Accuracy: 0.26058 %\n",
            "Test loss: 0.00134 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00096 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00134 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00075 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00075 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00131 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00149 | Test Accuracy: 0.25043 %\n",
            "Test loss: 0.00073 | Test Accuracy: 0.30032 %\n",
            "Test loss: 0.00195 | Test Accuracy: 0.24058 %\n",
            "Test loss: 0.00248 | Test Accuracy: 0.24039 %\n",
            "Test loss: 0.00106 | Test Accuracy: 0.28032 %\n",
            "Test loss: 0.00075 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00063 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00167 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00153 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00057 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00095 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00125 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00105 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00153 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00128 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00084 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00155 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00095 | Test Accuracy: 0.28038 %\n",
            "Test loss: 0.00184 | Test Accuracy: 0.23053 %\n",
            "Test loss: 0.00087 | Test Accuracy: 0.28029 %\n",
            "Test loss: 0.00028 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00106 | Test Accuracy: 0.27056 %\n",
            "Test loss: 0.00207 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00084 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00158 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00112 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00117 | Test Accuracy: 0.28039 %\n",
            "Test loss: 0.00105 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00054 | Test Accuracy: 0.30045 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [01:53<02:50, 56.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.00053 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00123 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00129 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00163 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00073 | Test Accuracy: 0.28035 %\n",
            "Epoch: 2\n",
            "------------\n",
            "Train loss: 0.32588 | Train accuracy: 88.12833%\n",
            "Test loss: 0.00154 | Test Accuracy: 0.27955 %\n",
            "Test loss: 0.00101 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00046 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00079 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00133 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00056 | Test Accuracy: 0.32029 %\n",
            "Test loss: 0.00105 | Test Accuracy: 0.27059 %\n",
            "Test loss: 0.00087 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00112 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.27056 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00161 | Test Accuracy: 0.25050 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00146 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00074 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00093 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00234 | Test Accuracy: 0.23053 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.29027 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00113 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00103 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00112 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00171 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00108 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00093 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00087 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00082 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00158 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00139 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00055 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00072 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00105 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00194 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00058 | Test Accuracy: 0.31034 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00170 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.30039 %\n",
            "Test loss: 0.00073 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00086 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00051 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00110 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00190 | Test Accuracy: 0.24045 %\n",
            "Test loss: 0.00123 | Test Accuracy: 0.28032 %\n",
            "Test loss: 0.00113 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00106 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00031 | Test Accuracy: 0.32042 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.30054 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00046 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00038 | Test Accuracy: 0.32045 %\n",
            "Test loss: 0.00131 | Test Accuracy: 0.27059 %\n",
            "Test loss: 0.00121 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00073 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00198 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00112 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00110 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00186 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00135 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00103 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00125 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00060 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00060 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00168 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00223 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00194 | Test Accuracy: 0.24042 %\n",
            "Test loss: 0.00130 | Test Accuracy: 0.28032 %\n",
            "Test loss: 0.00106 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00127 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00103 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00032 | Test Accuracy: 0.32045 %\n",
            "Test loss: 0.00160 | Test Accuracy: 0.24064 %\n",
            "Test loss: 0.00122 | Test Accuracy: 0.28032 %\n",
            "Test loss: 0.00213 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00162 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00060 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00192 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00113 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00085 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00108 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00053 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00103 | Test Accuracy: 0.27056 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00151 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00101 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00108 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00135 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00125 | Test Accuracy: 0.26039 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00157 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00165 | Test Accuracy: 0.22051 %\n",
            "Test loss: 0.00149 | Test Accuracy: 0.25031 %\n",
            "Test loss: 0.00226 | Test Accuracy: 0.22045 %\n",
            "Test loss: 0.00056 | Test Accuracy: 0.31021 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00174 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00100 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00031 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00043 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00106 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.30039 %\n",
            "Test loss: 0.00079 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00052 | Test Accuracy: 0.32042 %\n",
            "Test loss: 0.00077 | Test Accuracy: 0.30054 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00204 | Test Accuracy: 0.24045 %\n",
            "Test loss: 0.00068 | Test Accuracy: 0.30029 %\n",
            "Test loss: 0.00095 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00193 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.26039 %\n",
            "Test loss: 0.00131 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00143 | Test Accuracy: 0.25046 %\n",
            "Test loss: 0.00093 | Test Accuracy: 0.30032 %\n",
            "Test loss: 0.00050 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00156 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00123 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00154 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00093 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00140 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00041 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00189 | Test Accuracy: 0.26058 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.28039 %\n",
            "Test loss: 0.00164 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00045 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00096 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00218 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00278 | Test Accuracy: 0.23050 %\n",
            "Test loss: 0.00084 | Test Accuracy: 0.29027 %\n",
            "Test loss: 0.00266 | Test Accuracy: 0.24054 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.29031 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00177 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00064 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00159 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00025 | Test Accuracy: 0.32042 %\n",
            "Test loss: 0.00064 | Test Accuracy: 0.31053 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00146 | Test Accuracy: 0.25050 %\n",
            "Test loss: 0.00150 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00128 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00048 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.30039 %\n",
            "Test loss: 0.00144 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00086 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00077 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00101 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00134 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00085 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00057 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00103 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00127 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00150 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00084 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00151 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00155 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00110 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00135 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00127 | Test Accuracy: 0.25046 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00100 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00072 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00075 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00079 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.27056 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00130 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00031 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00057 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00079 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00074 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00058 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00058 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00085 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00105 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00119 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00143 | Test Accuracy: 0.25046 %\n",
            "Test loss: 0.00127 | Test Accuracy: 0.25040 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00053 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00039 | Test Accuracy: 0.32032 %\n",
            "Test loss: 0.00130 | Test Accuracy: 0.26061 %\n",
            "Test loss: 0.00057 | Test Accuracy: 0.31034 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00096 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00074 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00058 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00075 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00075 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00068 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00108 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00072 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00156 | Test Accuracy: 0.25043 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.30032 %\n",
            "Test loss: 0.00174 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00214 | Test Accuracy: 0.23046 %\n",
            "Test loss: 0.00086 | Test Accuracy: 0.28029 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00057 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00127 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00160 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00058 | Test Accuracy: 0.31031 %\n",
            "Test loss: 0.00082 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00082 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00121 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00117 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00132 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00165 | Test Accuracy: 0.24042 %\n",
            "Test loss: 0.00075 | Test Accuracy: 0.29030 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00156 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00085 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00165 | Test Accuracy: 0.24054 %\n",
            "Test loss: 0.00055 | Test Accuracy: 0.30029 %\n",
            "Test loss: 0.00047 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00174 | Test Accuracy: 0.27046 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [02:47<01:50, 55.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.00079 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00123 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00147 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00084 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00103 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00106 | Test Accuracy: 0.25050 %\n",
            "Test loss: 0.00073 | Test Accuracy: 0.30032 %\n",
            "Test loss: 0.00074 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00049 | Test Accuracy: 0.31050 %\n",
            "Test loss: 0.00065 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00096 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00162 | Test Accuracy: 0.24054 %\n",
            "Test loss: 0.00068 | Test Accuracy: 0.32026 %\n",
            "Epoch: 3\n",
            "------------\n",
            "Train loss: 0.30489 | Train accuracy: 88.91667%\n",
            "Test loss: 0.00147 | Test Accuracy: 0.27955 %\n",
            "Test loss: 0.00119 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00046 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00132 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00057 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00041 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.25059 %\n",
            "Test loss: 0.00038 | Test Accuracy: 0.31031 %\n",
            "Test loss: 0.00061 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00117 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00087 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00170 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00063 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00139 | Test Accuracy: 0.25059 %\n",
            "Test loss: 0.00123 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.24051 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.30029 %\n",
            "Test loss: 0.00064 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00112 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00213 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00135 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00145 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00121 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00077 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00191 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00123 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00105 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00093 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00056 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00057 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00157 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00082 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00153 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00086 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00198 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00112 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00096 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00064 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00025 | Test Accuracy: 0.31050 %\n",
            "Test loss: 0.00077 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00058 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00058 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00129 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00168 | Test Accuracy: 0.25050 %\n",
            "Test loss: 0.00123 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00045 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00209 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00155 | Test Accuracy: 0.25040 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00106 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00192 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00157 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00086 | Test Accuracy: 0.28038 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.28038 %\n",
            "Test loss: 0.00073 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00048 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00169 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00203 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00174 | Test Accuracy: 0.25043 %\n",
            "Test loss: 0.00161 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00180 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00155 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00110 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00033 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00167 | Test Accuracy: 0.27056 %\n",
            "Test loss: 0.00096 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00192 | Test Accuracy: 0.24051 %\n",
            "Test loss: 0.00172 | Test Accuracy: 0.24039 %\n",
            "Test loss: 0.00123 | Test Accuracy: 0.28032 %\n",
            "Test loss: 0.00134 | Test Accuracy: 0.25050 %\n",
            "Test loss: 0.00053 | Test Accuracy: 0.31031 %\n",
            "Test loss: 0.00061 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00085 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00192 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00187 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00121 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00085 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00039 | Test Accuracy: 0.32042 %\n",
            "Test loss: 0.00112 | Test Accuracy: 0.27059 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00125 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00149 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00123 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00064 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00154 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00100 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00169 | Test Accuracy: 0.25046 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00223 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00051 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00174 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00032 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00043 | Test Accuracy: 0.31050 %\n",
            "Test loss: 0.00054 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00063 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00060 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00049 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00131 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00153 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00063 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00178 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00138 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00086 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00144 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00105 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00190 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00135 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00166 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00100 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00119 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00125 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00108 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00037 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00244 | Test Accuracy: 0.25059 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00212 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00025 | Test Accuracy: 0.32032 %\n",
            "Test loss: 0.00084 | Test Accuracy: 0.30054 %\n",
            "Test loss: 0.00117 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00199 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00300 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00050 | Test Accuracy: 0.31034 %\n",
            "Test loss: 0.00303 | Test Accuracy: 0.23062 %\n",
            "Test loss: 0.00132 | Test Accuracy: 0.28029 %\n",
            "Test loss: 0.00096 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00152 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00053 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00050 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00134 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00028 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00060 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00148 | Test Accuracy: 0.24051 %\n",
            "Test loss: 0.00139 | Test Accuracy: 0.28032 %\n",
            "Test loss: 0.00117 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00085 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00061 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00125 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00079 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00054 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00142 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00112 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00042 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00086 | Test Accuracy: 0.27056 %\n",
            "Test loss: 0.00138 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00162 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00077 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00161 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00121 | Test Accuracy: 0.28038 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00048 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00055 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00084 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00072 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00106 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00065 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00079 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00082 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00045 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00053 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00010 | Test Accuracy: 0.32042 %\n",
            "Test loss: 0.00063 | Test Accuracy: 0.31053 %\n",
            "Test loss: 0.00063 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00075 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00142 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00077 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00045 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00045 | Test Accuracy: 0.31050 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00138 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00085 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00060 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00140 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00168 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00046 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00150 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00019 | Test Accuracy: 0.32032 %\n",
            "Test loss: 0.00138 | Test Accuracy: 0.27059 %\n",
            "Test loss: 0.00045 | Test Accuracy: 0.30039 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00072 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00075 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00082 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00129 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00131 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00082 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00196 | Test Accuracy: 0.21059 %\n",
            "Test loss: 0.00197 | Test Accuracy: 0.26026 %\n",
            "Test loss: 0.00082 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00061 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00144 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00172 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00032 | Test Accuracy: 0.32038 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.30054 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00147 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00110 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00119 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00079 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00184 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00065 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00168 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00055 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00203 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00065 | Test Accuracy: 0.30032 %\n",
            "Test loss: 0.00159 | Test Accuracy: 0.24058 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [03:41<00:54, 54.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.00148 | Test Accuracy: 0.27034 %\n",
            "Test loss: 0.00073 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00085 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00048 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00061 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00052 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00108 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00055 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00148 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.28042 %\n",
            "Epoch: 4\n",
            "------------\n",
            "Train loss: 0.28981 | Train accuracy: 89.56333%\n",
            "Test loss: 0.00215 | Test Accuracy: 0.26957 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00065 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00030 | Test Accuracy: 0.31050 %\n",
            "Test loss: 0.00118 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00063 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00050 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00040 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00068 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00053 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00085 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00134 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.31050 %\n",
            "Test loss: 0.00129 | Test Accuracy: 0.26058 %\n",
            "Test loss: 0.00128 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00142 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00082 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00038 | Test Accuracy: 0.32045 %\n",
            "Test loss: 0.00112 | Test Accuracy: 0.28058 %\n",
            "Test loss: 0.00129 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00201 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00049 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00145 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00100 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00134 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00077 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00133 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.28039 %\n",
            "Test loss: 0.00101 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00117 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00074 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00142 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00103 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00130 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00031 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00047 | Test Accuracy: 0.31050 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00177 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00095 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00157 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00058 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00058 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00068 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00182 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00118 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00064 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00025 | Test Accuracy: 0.32045 %\n",
            "Test loss: 0.00052 | Test Accuracy: 0.31053 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00038 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00046 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00117 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00164 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.28039 %\n",
            "Test loss: 0.00061 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00046 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00206 | Test Accuracy: 0.25059 %\n",
            "Test loss: 0.00135 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00185 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00119 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00113 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00061 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00177 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00171 | Test Accuracy: 0.24051 %\n",
            "Test loss: 0.00186 | Test Accuracy: 0.27034 %\n",
            "Test loss: 0.00164 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00157 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00130 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00084 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00055 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00146 | Test Accuracy: 0.25059 %\n",
            "Test loss: 0.00093 | Test Accuracy: 0.30032 %\n",
            "Test loss: 0.00181 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00139 | Test Accuracy: 0.23046 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.28029 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00049 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00191 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00127 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00172 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00139 | Test Accuracy: 0.28038 %\n",
            "Test loss: 0.00068 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00037 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.27056 %\n",
            "Test loss: 0.00086 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00154 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00154 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00049 | Test Accuracy: 0.31050 %\n",
            "Test loss: 0.00132 | Test Accuracy: 0.26058 %\n",
            "Test loss: 0.00093 | Test Accuracy: 0.28039 %\n",
            "Test loss: 0.00056 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00147 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00152 | Test Accuracy: 0.25040 %\n",
            "Test loss: 0.00117 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00198 | Test Accuracy: 0.23053 %\n",
            "Test loss: 0.00046 | Test Accuracy: 0.29027 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00158 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00064 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00065 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00025 | Test Accuracy: 0.32038 %\n",
            "Test loss: 0.00037 | Test Accuracy: 0.30054 %\n",
            "Test loss: 0.00060 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00072 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00106 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00053 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00072 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00046 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00096 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00166 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00086 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00133 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00139 | Test Accuracy: 0.25046 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00130 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00112 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00153 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00183 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00158 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00125 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00040 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00202 | Test Accuracy: 0.26058 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00167 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00026 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00079 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00159 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00304 | Test Accuracy: 0.22054 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.29024 %\n",
            "Test loss: 0.00300 | Test Accuracy: 0.23056 %\n",
            "Test loss: 0.00110 | Test Accuracy: 0.28029 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00132 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00027 | Test Accuracy: 0.31034 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00168 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00093 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00036 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00127 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00087 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00054 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00072 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00108 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00055 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00053 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00103 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00074 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00163 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00147 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00072 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00173 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00128 | Test Accuracy: 0.26039 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.28038 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00143 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00101 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00034 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00065 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00084 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00075 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00068 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00079 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00135 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00052 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.31050 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.27056 %\n",
            "Test loss: 0.00055 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00056 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00105 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00014 | Test Accuracy: 0.32042 %\n",
            "Test loss: 0.00033 | Test Accuracy: 0.31053 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.31050 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00132 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00049 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00033 | Test Accuracy: 0.32048 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.30054 %\n",
            "Test loss: 0.00073 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00095 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00130 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00135 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00162 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00139 | Test Accuracy: 0.28038 %\n",
            "Test loss: 0.00087 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00057 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00158 | Test Accuracy: 0.24058 %\n",
            "Test loss: 0.00027 | Test Accuracy: 0.32026 %\n",
            "Test loss: 0.00161 | Test Accuracy: 0.25062 %\n",
            "Test loss: 0.00032 | Test Accuracy: 0.31031 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.27056 %\n",
            "Test loss: 0.00095 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00045 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00052 | Test Accuracy: 0.31050 %\n",
            "Test loss: 0.00047 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00138 | Test Accuracy: 0.25046 %\n",
            "Test loss: 0.00061 | Test Accuracy: 0.30032 %\n",
            "Test loss: 0.00145 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00193 | Test Accuracy: 0.25040 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00050 | Test Accuracy: 0.32042 %\n",
            "Test loss: 0.00054 | Test Accuracy: 0.30054 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00147 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00135 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00032 | Test Accuracy: 0.32035 %\n",
            "Test loss: 0.00061 | Test Accuracy: 0.30054 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00169 | Test Accuracy: 0.22048 %\n",
            "Test loss: 0.00074 | Test Accuracy: 0.31021 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00143 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00050 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00151 | Test Accuracy: 0.24058 %\n",
            "Test loss: 0.00082 | Test Accuracy: 0.27034 %\n",
            "Test loss: 0.00046 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00110 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00131 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00060 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00151 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00074 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00129 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00053 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00033 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00035 | Test Accuracy: 0.32048 %\n",
            "Test loss: 0.00029 | Test Accuracy: 0.31053 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [04:36<00:00, 55.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.00071 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00049 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00143 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00187 | Test Accuracy: 0.24051 %\n",
            "Test loss: 0.00075 | Test Accuracy: 0.30029 %\n",
            "Training time: 276.0380973749998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label."
      ],
      "metadata": {
        "id": "w1CsHhPpxp1w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_YGgZvSobNxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Plot a confusion matrix comparing your model's predictions to the truth labels."
      ],
      "metadata": {
        "id": "qQwzqlBWxrpG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vSrXiT_AbQ6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?"
      ],
      "metadata": {
        "id": "lj6bDhoWxt2y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "leCTsqtSbR5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. Use a model similar to the trained `model_2` from notebook 03 to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset.\n",
        "* Then plot some predictions where the model was wrong alongside what the label of the image should've been.\n",
        "* After visualing these predictions do you think it's more of a modelling error or a data error?\n",
        "* As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
      ],
      "metadata": {
        "id": "VHS20cNTxwSi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "78a8LjtdbSZj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}