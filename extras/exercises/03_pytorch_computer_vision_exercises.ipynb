{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_pytorch_computer_vision_exercises.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sofpast/pytorch-deep-learning/blob/main/extras/exercises/03_pytorch_computer_vision_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 03. PyTorch Computer Vision Exercises\n",
        "\n",
        "The following is a collection of exercises based on computer vision fundamentals in PyTorch.\n",
        "\n",
        "They're a bunch of fun.\n",
        "\n",
        "You're going to get to write plenty of code!\n",
        "\n",
        "## Resources\n",
        "\n",
        "1. These exercises are based on [notebook 03 of the Learn PyTorch for Deep Learning course](https://www.learnpytorch.io/03_pytorch_computer_vision/).\n",
        "2. See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/_PibmqpEyhA).\n",
        "  * **Note:** Going through these exercises took me just over 3 hours of solid coding, so you should expect around the same.\n",
        "3. See [other solutions on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions)."
      ],
      "metadata": {
        "id": "Vex99np2wFVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaeYzOTLwWh2",
        "outputId": "7507429a-f77b-46a8-c532-0156a33c6015"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import torch\n",
        "import torch\n",
        "\n",
        "# Exercises require PyTorch > 1.10.0\n",
        "print(torch.__version__)\n",
        "\n",
        "# TODO: Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() is True else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "DNwZLMbCzJLk",
        "outputId": "c9ca3c25-3fc8-43af-85f5-ae8349a9ca33"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu118\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. What are 3 areas in industry where computer vision is currently being used?"
      ],
      "metadata": {
        "id": "FSFX7tc1w-en"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# camera apps, modern cars, and manufacturers"
      ],
      "metadata": {
        "id": "VyWRkvWGbCXj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find."
      ],
      "metadata": {
        "id": "oBK-WI6YxDYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Overfitting means our model is learning the training data well but those patterns aren't generalizing to the testing data."
      ],
      "metadata": {
        "id": "d1rxD6GObCqh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each.\n",
        "> **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those."
      ],
      "metadata": {
        "id": "XeYFEqw8xK26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Two of main to fix overfitting include:\n",
        "# 1. Using a smaller or different model\n",
        "# 2. Using a larger dataset"
      ],
      "metadata": {
        "id": "ocvOdWKcbEKr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
        "\n",
        "* Upload your own example image using the \"upload\" button on the website and see what happens in each layer of a CNN as your image passes through it."
      ],
      "metadata": {
        "id": "DKdEEFEqxM-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "m = nn.Softmax(dim=1)\n",
        "input = torch.randn(1, 4)\n",
        "print(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dre_6KzaNKdc",
        "outputId": "38a20554-bc56-4532-c28c-d9e5f89403cf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5161, 1.7055, 0.9420, 0.9916]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = m(input)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qb27-AvOCiZ",
        "outputId": "1602122e-3471-4b13-e6af-06ab19f90bce"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1347, 0.4424, 0.2062, 0.2167]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets."
      ],
      "metadata": {
        "id": "lvf-3pODxXYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Import torchvision\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Import matplotlib for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check version\n",
        "print(f\"PyTorch version: {torch.__version__}\\ntorchvision: {torchvision.__version__}\")\n"
      ],
      "metadata": {
        "id": "SHjeuN81bHza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07922020-1f93-4259-84eb-f8dc6f3a796e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.1.0+cu118\n",
            "torchvision: 0.16.0+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "# Testing data\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKIJCjnTVgJv",
        "outputId": "88cead9f-b66b-4755-8ca1-b3835de2cc81"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 19193016.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 301490.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5567516.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 6070361.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[0]\n",
        "image, label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LWEfOxfWHH3",
        "outputId": "767965ce-103b-47b0-e17e-6ce78b7e5935"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
              "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
              "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
              "           0.0157, 0.0000, 0.0000, 0.0118],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
              "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0471, 0.0392, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
              "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
              "           0.3020, 0.5098, 0.2824, 0.0588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
              "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
              "           0.5529, 0.3451, 0.6745, 0.2588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
              "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
              "           0.4824, 0.7686, 0.8980, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
              "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
              "           0.8745, 0.9608, 0.6784, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
              "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
              "           0.8627, 0.9529, 0.7922, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
              "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
              "           0.8863, 0.7725, 0.8196, 0.2039],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
              "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
              "           0.9608, 0.4667, 0.6549, 0.2196],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
              "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
              "           0.8510, 0.8196, 0.3608, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
              "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
              "           0.8549, 1.0000, 0.3020, 0.0000],\n",
              "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
              "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
              "           0.8784, 0.9569, 0.6235, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
              "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
              "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
              "           0.9137, 0.9333, 0.8431, 0.0000],\n",
              "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
              "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
              "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
              "           0.8627, 0.9098, 0.9647, 0.0000],\n",
              "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
              "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
              "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
              "           0.8706, 0.8941, 0.8824, 0.0000],\n",
              "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
              "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
              "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
              "           0.8745, 0.8784, 0.8980, 0.1137],\n",
              "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
              "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
              "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
              "           0.8627, 0.8667, 0.9020, 0.2627],\n",
              "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
              "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
              "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
              "           0.7098, 0.8039, 0.8078, 0.4510],\n",
              "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
              "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
              "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
              "           0.6549, 0.6941, 0.8235, 0.3608],\n",
              "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
              "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
              "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
              "           0.7529, 0.8471, 0.6667, 0.0000],\n",
              "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
              "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
              "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
              "           0.3882, 0.2275, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
              "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
              " 9)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(image.shape)\n",
        "print(len(train_data.data), len(train_data.targets), len(test_data.data), len(test_data.targets))\n",
        "class_names = train_data.classes\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hHucO4FWP3z",
        "outputId": "1b6a8894-bb05-44e8-f4c9-f287983e7e19"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "60000 60000 10000 10000\n",
            "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Visualize at least 5 different samples of the MNIST training dataset."
      ],
      "metadata": {
        "id": "qxZW-uAbxe_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot image\n",
        "torch.manual_seed(23)\n",
        "fig = plt.figure(figsize=(9, 9))\n",
        "rows, cols = 4, 4\n",
        "for i in range(1, rows * cols + 1):\n",
        "  random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
        "  img, label = train_data[random_idx]\n",
        "  fig.add_subplot(rows, cols, i)\n",
        "  plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "  plt.title(class_names[label])\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "QVFsYi1PbItE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "outputId": "39ceebad-24c0-46b6-d786-7274d1420ac3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x900 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`."
      ],
      "metadata": {
        "id": "JAPDzW0wxhi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Turn datasets into iterables (batches)\n",
        "train_dataloader = DataLoader(\n",
        "    train_data,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_data,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = False\n",
        ")\n",
        "\n",
        "print(f\"Dataloaders: {train_dataloader, test_dataloader}\")\n",
        "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
        "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")\n"
      ],
      "metadata": {
        "id": "ALA6MPcFbJXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d497577-efc2-4ab0-e350-940a7445b132"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x7c3318e5f1c0>, <torch.utils.data.dataloader.DataLoader object at 0x7c3318e5eb00>)\n",
            "Length of train dataloader: 1875 batches of 32\n",
            "Length of test dataloader: 313 batches of 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Recreate `model_2` used in notebook 03 (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset."
      ],
      "metadata": {
        "id": "bCCVfXk5xjYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionMNISTModelV2(nn.Module):\n",
        "  def __init__(self, input_shape: int, output_shape: int, hidden_units: int):\n",
        "    super().__init__()\n",
        "    self.block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(\n",
        "            kernel_size=2,\n",
        "            stride=2\n",
        "        )\n",
        "    )\n",
        "    self.block_2 = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels=hidden_units,\n",
        "            out_channels=hidden_units,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1\n",
        "        ),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(\n",
        "            kernel_size=2\n",
        "        )\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(\n",
        "            in_features=hidden_units*7*7,\n",
        "            out_features=output_shape\n",
        "        )\n",
        "    )\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    x = self.block_1(x)\n",
        "    x = self.block_2(x)\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model_2 = FashionMNISTModelV2(input_shape=1,\n",
        "                              hidden_units=10,\n",
        "                              output_shape=len(class_names)).to(device)\n",
        "model_2\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5IKNF22XbKYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b6637ab-dddd-4d52-c578-1e5e650a6909"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FashionMNISTModelV2(\n",
              "  (block_1): Sequential(\n",
              "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block_2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Train the model you built in exercise 8. for 5 epochs on CPU and GPU and see how long it takes on each."
      ],
      "metadata": {
        "id": "sf_3zUr7xlhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_2.parameters(),\n",
        "                            lr=0.1)"
      ],
      "metadata": {
        "id": "jSo6vVWFbNLD"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper_functions.py already exists, skipping download\")\n",
        "else:\n",
        "  print(\"Downloading helper_functions.py\")\n",
        "  # Note: you need the \"raw\" GitHub URL for this to work\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)\n",
        "# Import accuracy metric\n",
        "from helper_functions import accuracy_fn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFsbjHEvWf4D",
        "outputId": "97096c58-866c-4ed2-ddb4-191d9cfe56fb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "helper_functions.py already exists, skipping download\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_step\n",
        "def train_step(\n",
        "    model: torch.nn.Module,\n",
        "    data_loader: torch.utils.data.DataLoader,\n",
        "    loss_fn: torch.nn.Module,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    accuracy_fn,\n",
        "    device: torch.device = device):\n",
        "\n",
        "  train_loss, train_acc = 0, 0\n",
        "  model.to(device)\n",
        "\n",
        "  for batch, (X, y) in enumerate(data_loader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    y_pred = model(X)\n",
        "\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss\n",
        "    train_acc += accuracy_fn(y_true=y,\n",
        "                            y_pred = y_pred.argmax(dim=1))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  train_loss /= len(data_loader)\n",
        "  train_acc /= len(data_loader)\n",
        "  print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.5f}%\")\n",
        "\n",
        "def test_step(data_loader: torch.utils.data.DataLoader,\n",
        "              model: torch.nn.Module,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              accuracy_fn,\n",
        "              device: torch.device = device):\n",
        "  test_loss, test_acc = 0, 0\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for X, y in data_loader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      test_pred = model(X)\n",
        "\n",
        "      test_loss += loss_fn(test_pred, y)\n",
        "      test_acc += accuracy_fn(y_true=y,\n",
        "                              y_pred=test_pred.argmax(dim=1)\n",
        "                              )\n",
        "      test_loss /= len(data_loader)\n",
        "      test_acc /= len(data_loader)\n",
        "      print(f\"Test loss: {test_loss:.5f} | Test Accuracy: {test_acc:.5f} %\")\n",
        "\n"
      ],
      "metadata": {
        "id": "n6AJHH9VR5VT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training model\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "from tqdm import tqdm\n",
        "start_time = timer()\n",
        "epochs = 5\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n------------\")\n",
        "  train_step(data_loader=train_dataloader,\n",
        "            model=model_2,\n",
        "            loss_fn=loss_fn,\n",
        "            optimizer=optimizer,\n",
        "            accuracy_fn=accuracy_fn\n",
        "             )\n",
        "  test_step(\n",
        "      data_loader=test_dataloader,\n",
        "      model=model_2,\n",
        "      loss_fn=loss_fn,\n",
        "      accuracy_fn=accuracy_fn\n",
        "  )\n",
        "\n",
        "end_time = timer()\n",
        "\n",
        "print(f\"Training time: {end_time - start_time}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDV1oYybVCBS",
        "outputId": "46eebacd-c8c3-4c3b-cb1f-c5c0efa56427"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "------------\n",
            "Train loss: 0.59518 | Train accuracy: 78.37500%\n",
            "Test loss: 0.00157 | Test Accuracy: 0.25958 %\n",
            "Test loss: 0.00154 | Test Accuracy: 0.25043 %\n",
            "Test loss: 0.00117 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00061 | Test Accuracy: 0.32038 %\n",
            "Test loss: 0.00131 | Test Accuracy: 0.28058 %\n",
            "Test loss: 0.00057 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00142 | Test Accuracy: 0.24061 %\n",
            "Test loss: 0.00068 | Test Accuracy: 0.32026 %\n",
            "Test loss: 0.00095 | Test Accuracy: 0.27059 %\n",
            "Test loss: 0.00112 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00139 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00165 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00160 | Test Accuracy: 0.23059 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.28029 %\n",
            "Test loss: 0.00192 | Test Accuracy: 0.25050 %\n",
            "Test loss: 0.00112 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00150 | Test Accuracy: 0.28039 %\n",
            "Test loss: 0.00147 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00123 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00113 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00128 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00247 | Test Accuracy: 0.22054 %\n",
            "Test loss: 0.00156 | Test Accuracy: 0.27027 %\n",
            "Test loss: 0.00110 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00168 | Test Accuracy: 0.25043 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00122 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00164 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00138 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00127 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00123 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00144 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00101 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00127 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00225 | Test Accuracy: 0.24048 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.30029 %\n",
            "Test loss: 0.00113 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00181 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.31034 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.27056 %\n",
            "Test loss: 0.00167 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00073 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00155 | Test Accuracy: 0.25050 %\n",
            "Test loss: 0.00190 | Test Accuracy: 0.25040 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00199 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00110 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00152 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00044 | Test Accuracy: 0.32035 %\n",
            "Test loss: 0.00065 | Test Accuracy: 0.31053 %\n",
            "Test loss: 0.00156 | Test Accuracy: 0.25059 %\n",
            "Test loss: 0.00174 | Test Accuracy: 0.26039 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00122 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00131 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00154 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00151 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.28038 %\n",
            "Test loss: 0.00203 | Test Accuracy: 0.25050 %\n",
            "Test loss: 0.00158 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00135 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00096 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00180 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00140 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00236 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00191 | Test Accuracy: 0.24045 %\n",
            "Test loss: 0.00170 | Test Accuracy: 0.28032 %\n",
            "Test loss: 0.00121 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00118 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00145 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00043 | Test Accuracy: 0.32038 %\n",
            "Test loss: 0.00180 | Test Accuracy: 0.25062 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.26039 %\n",
            "Test loss: 0.00265 | Test Accuracy: 0.22048 %\n",
            "Test loss: 0.00184 | Test Accuracy: 0.25031 %\n",
            "Test loss: 0.00173 | Test Accuracy: 0.24042 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.27034 %\n",
            "Test loss: 0.00063 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00085 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00131 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00261 | Test Accuracy: 0.23046 %\n",
            "Test loss: 0.00154 | Test Accuracy: 0.27030 %\n",
            "Test loss: 0.00158 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00113 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00144 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00082 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00145 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00125 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00145 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00119 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00142 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00155 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00182 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00180 | Test Accuracy: 0.24045 %\n",
            "Test loss: 0.00156 | Test Accuracy: 0.25037 %\n",
            "Test loss: 0.00241 | Test Accuracy: 0.25040 %\n",
            "Test loss: 0.00108 | Test Accuracy: 0.25040 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.30032 %\n",
            "Test loss: 0.00186 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00106 | Test Accuracy: 0.28039 %\n",
            "Test loss: 0.00095 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00048 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00142 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00230 | Test Accuracy: 0.23043 %\n",
            "Test loss: 0.00087 | Test Accuracy: 0.30026 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00075 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00232 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00160 | Test Accuracy: 0.24042 %\n",
            "Test loss: 0.00143 | Test Accuracy: 0.27034 %\n",
            "Test loss: 0.00152 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00127 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00179 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00150 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00163 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00149 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00134 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00144 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00209 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00194 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00049 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00084 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00180 | Test Accuracy: 0.24051 %\n",
            "Test loss: 0.00157 | Test Accuracy: 0.28032 %\n",
            "Test loss: 0.00308 | Test Accuracy: 0.23053 %\n",
            "Test loss: 0.00077 | Test Accuracy: 0.29027 %\n",
            "Test loss: 0.00300 | Test Accuracy: 0.20061 %\n",
            "Test loss: 0.00119 | Test Accuracy: 0.29018 %\n",
            "Test loss: 0.00130 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00123 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00183 | Test Accuracy: 0.24045 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.29030 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00195 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.28039 %\n",
            "Test loss: 0.00033 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00101 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00167 | Test Accuracy: 0.23056 %\n",
            "Test loss: 0.00122 | Test Accuracy: 0.29027 %\n",
            "Test loss: 0.00194 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00060 | Test Accuracy: 0.30032 %\n",
            "Test loss: 0.00150 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00122 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00145 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00086 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00122 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00205 | Test Accuracy: 0.25046 %\n",
            "Test loss: 0.00131 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00119 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00127 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00148 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00119 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00164 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00209 | Test Accuracy: 0.25043 %\n",
            "Test loss: 0.00152 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00125 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00171 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00162 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00072 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00106 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00113 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00154 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00135 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00127 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00143 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00068 | Test Accuracy: 0.30032 %\n",
            "Test loss: 0.00142 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00105 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00129 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00106 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00160 | Test Accuracy: 0.24048 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.28032 %\n",
            "Test loss: 0.00082 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00130 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00029 | Test Accuracy: 0.32042 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.29056 %\n",
            "Test loss: 0.00112 | Test Accuracy: 0.29047 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00133 | Test Accuracy: 0.25050 %\n",
            "Test loss: 0.00151 | Test Accuracy: 0.26038 %\n",
            "Test loss: 0.00147 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.31034 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00159 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.25046 %\n",
            "Test loss: 0.00144 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00103 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00150 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00134 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00134 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00144 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00162 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00060 | Test Accuracy: 0.30032 %\n",
            "Test loss: 0.00151 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00145 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00128 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00086 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00096 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00085 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00121 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00184 | Test Accuracy: 0.24054 %\n",
            "Test loss: 0.00150 | Test Accuracy: 0.27034 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00211 | Test Accuracy: 0.21059 %\n",
            "Test loss: 0.00282 | Test Accuracy: 0.21034 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.28022 %\n",
            "Test loss: 0.00093 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00148 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00178 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00129 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00087 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00163 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00101 | Test Accuracy: 0.28038 %\n",
            "Test loss: 0.00162 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00204 | Test Accuracy: 0.23046 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.29027 %\n",
            "Test loss: 0.00149 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00160 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00122 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00122 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00177 | Test Accuracy: 0.23053 %\n",
            "Test loss: 0.00100 | Test Accuracy: 0.28029 %\n",
            "Test loss: 0.00048 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00128 | Test Accuracy: 0.27056 %\n",
            "Test loss: 0.00198 | Test Accuracy: 0.25047 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.26038 %\n",
            "Test loss: 0.00153 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00180 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00117 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00153 | Test Accuracy: 0.23056 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.29027 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.30039 %\n",
            "Test loss: 0.00049 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00153 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.28042 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 1/5 [00:57<03:49, 57.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.00124 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00166 | Test Accuracy: 0.24051 %\n",
            "Test loss: 0.00108 | Test Accuracy: 0.30029 %\n",
            "Epoch: 1\n",
            "------------\n",
            "Train loss: 0.36536 | Train accuracy: 86.90167%\n",
            "Test loss: 0.00157 | Test Accuracy: 0.27955 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00065 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00139 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00043 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00073 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00135 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00046 | Test Accuracy: 0.32029 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.27059 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00086 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00145 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00129 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00172 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00087 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00151 | Test Accuracy: 0.24058 %\n",
            "Test loss: 0.00158 | Test Accuracy: 0.28032 %\n",
            "Test loss: 0.00123 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00139 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00085 | Test Accuracy: 0.28038 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00100 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.28038 %\n",
            "Test loss: 0.00241 | Test Accuracy: 0.23053 %\n",
            "Test loss: 0.00164 | Test Accuracy: 0.27031 %\n",
            "Test loss: 0.00086 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00073 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00169 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00174 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.28038 %\n",
            "Test loss: 0.00121 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00095 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00142 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00131 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00132 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00050 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00209 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00054 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00095 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00167 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00074 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00122 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00132 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00231 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00138 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00040 | Test Accuracy: 0.32045 %\n",
            "Test loss: 0.00064 | Test Accuracy: 0.28058 %\n",
            "Test loss: 0.00106 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00046 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00049 | Test Accuracy: 0.32048 %\n",
            "Test loss: 0.00148 | Test Accuracy: 0.24064 %\n",
            "Test loss: 0.00158 | Test Accuracy: 0.25037 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00073 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00084 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00164 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00158 | Test Accuracy: 0.25046 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00178 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00167 | Test Accuracy: 0.25040 %\n",
            "Test loss: 0.00087 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00096 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00060 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00181 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00133 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00207 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00198 | Test Accuracy: 0.25043 %\n",
            "Test loss: 0.00160 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00117 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00144 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00121 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00038 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00167 | Test Accuracy: 0.25059 %\n",
            "Test loss: 0.00122 | Test Accuracy: 0.26039 %\n",
            "Test loss: 0.00207 | Test Accuracy: 0.23046 %\n",
            "Test loss: 0.00182 | Test Accuracy: 0.25034 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00064 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00072 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00220 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00117 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00173 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00101 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00121 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00132 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00118 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00129 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00105 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00154 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00079 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00130 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00143 | Test Accuracy: 0.25043 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00193 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00139 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00218 | Test Accuracy: 0.24048 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.29031 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00177 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00095 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00031 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00053 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00056 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00101 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00113 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00061 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00150 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00199 | Test Accuracy: 0.24051 %\n",
            "Test loss: 0.00087 | Test Accuracy: 0.28032 %\n",
            "Test loss: 0.00105 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00057 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00223 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00129 | Test Accuracy: 0.26039 %\n",
            "Test loss: 0.00129 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00146 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00054 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00191 | Test Accuracy: 0.26058 %\n",
            "Test loss: 0.00160 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00187 | Test Accuracy: 0.24045 %\n",
            "Test loss: 0.00096 | Test Accuracy: 0.28032 %\n",
            "Test loss: 0.00155 | Test Accuracy: 0.24051 %\n",
            "Test loss: 0.00131 | Test Accuracy: 0.28032 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00190 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00220 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00035 | Test Accuracy: 0.32035 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.30054 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00189 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00122 | Test Accuracy: 0.25040 %\n",
            "Test loss: 0.00304 | Test Accuracy: 0.23043 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.28029 %\n",
            "Test loss: 0.00292 | Test Accuracy: 0.23053 %\n",
            "Test loss: 0.00118 | Test Accuracy: 0.27031 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00149 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00046 | Test Accuracy: 0.32035 %\n",
            "Test loss: 0.00149 | Test Accuracy: 0.26061 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00028 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00082 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.25046 %\n",
            "Test loss: 0.00131 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00167 | Test Accuracy: 0.25046 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00100 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00056 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00063 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00145 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00135 | Test Accuracy: 0.28039 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00146 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00119 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00125 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00154 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00155 | Test Accuracy: 0.25043 %\n",
            "Test loss: 0.00140 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00139 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00130 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00134 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00056 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00110 | Test Accuracy: 0.27056 %\n",
            "Test loss: 0.00103 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00117 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.28038 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00108 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00137 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00084 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00074 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00038 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00087 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.25050 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00055 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00068 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00074 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00101 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00145 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00125 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00093 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00140 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00122 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00037 | Test Accuracy: 0.32035 %\n",
            "Test loss: 0.00156 | Test Accuracy: 0.26061 %\n",
            "Test loss: 0.00065 | Test Accuracy: 0.31034 %\n",
            "Test loss: 0.00133 | Test Accuracy: 0.26058 %\n",
            "Test loss: 0.00134 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00096 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00134 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00075 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00075 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00131 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00149 | Test Accuracy: 0.25043 %\n",
            "Test loss: 0.00073 | Test Accuracy: 0.30032 %\n",
            "Test loss: 0.00195 | Test Accuracy: 0.24058 %\n",
            "Test loss: 0.00248 | Test Accuracy: 0.24039 %\n",
            "Test loss: 0.00106 | Test Accuracy: 0.28032 %\n",
            "Test loss: 0.00075 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00063 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00167 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00153 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00057 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00095 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00125 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00105 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00153 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00128 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00084 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00155 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00095 | Test Accuracy: 0.28038 %\n",
            "Test loss: 0.00184 | Test Accuracy: 0.23053 %\n",
            "Test loss: 0.00087 | Test Accuracy: 0.28029 %\n",
            "Test loss: 0.00028 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00106 | Test Accuracy: 0.27056 %\n",
            "Test loss: 0.00207 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00084 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00158 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00112 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00117 | Test Accuracy: 0.28039 %\n",
            "Test loss: 0.00105 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00054 | Test Accuracy: 0.30045 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [01:53<02:50, 56.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.00053 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00123 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00129 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00163 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00073 | Test Accuracy: 0.28035 %\n",
            "Epoch: 2\n",
            "------------\n",
            "Train loss: 0.32588 | Train accuracy: 88.12833%\n",
            "Test loss: 0.00154 | Test Accuracy: 0.27955 %\n",
            "Test loss: 0.00101 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00046 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00079 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00133 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00056 | Test Accuracy: 0.32029 %\n",
            "Test loss: 0.00105 | Test Accuracy: 0.27059 %\n",
            "Test loss: 0.00087 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00112 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.27056 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00161 | Test Accuracy: 0.25050 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00146 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00074 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00093 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00234 | Test Accuracy: 0.23053 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.29027 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00113 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00103 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00112 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00171 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00108 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00093 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00087 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00082 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00158 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00139 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00055 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00072 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00105 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00194 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00058 | Test Accuracy: 0.31034 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00170 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.30039 %\n",
            "Test loss: 0.00073 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00086 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00051 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00110 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00190 | Test Accuracy: 0.24045 %\n",
            "Test loss: 0.00123 | Test Accuracy: 0.28032 %\n",
            "Test loss: 0.00113 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00106 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00031 | Test Accuracy: 0.32042 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.30054 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00046 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00038 | Test Accuracy: 0.32045 %\n",
            "Test loss: 0.00131 | Test Accuracy: 0.27059 %\n",
            "Test loss: 0.00121 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00073 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00198 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00112 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00110 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00186 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00135 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00103 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00125 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00060 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00060 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00168 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00223 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00194 | Test Accuracy: 0.24042 %\n",
            "Test loss: 0.00130 | Test Accuracy: 0.28032 %\n",
            "Test loss: 0.00106 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00127 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00103 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00032 | Test Accuracy: 0.32045 %\n",
            "Test loss: 0.00160 | Test Accuracy: 0.24064 %\n",
            "Test loss: 0.00122 | Test Accuracy: 0.28032 %\n",
            "Test loss: 0.00213 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00162 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00060 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00192 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00113 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00085 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00108 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00053 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00103 | Test Accuracy: 0.27056 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00151 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00101 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00108 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00135 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00125 | Test Accuracy: 0.26039 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00157 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00165 | Test Accuracy: 0.22051 %\n",
            "Test loss: 0.00149 | Test Accuracy: 0.25031 %\n",
            "Test loss: 0.00226 | Test Accuracy: 0.22045 %\n",
            "Test loss: 0.00056 | Test Accuracy: 0.31021 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00174 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00100 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00031 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00043 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00106 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.30039 %\n",
            "Test loss: 0.00079 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00052 | Test Accuracy: 0.32042 %\n",
            "Test loss: 0.00077 | Test Accuracy: 0.30054 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00204 | Test Accuracy: 0.24045 %\n",
            "Test loss: 0.00068 | Test Accuracy: 0.30029 %\n",
            "Test loss: 0.00095 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00193 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.26039 %\n",
            "Test loss: 0.00131 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00143 | Test Accuracy: 0.25046 %\n",
            "Test loss: 0.00093 | Test Accuracy: 0.30032 %\n",
            "Test loss: 0.00050 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00156 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00123 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00154 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00093 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00140 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00041 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00189 | Test Accuracy: 0.26058 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.28039 %\n",
            "Test loss: 0.00164 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00045 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00096 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00218 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00278 | Test Accuracy: 0.23050 %\n",
            "Test loss: 0.00084 | Test Accuracy: 0.29027 %\n",
            "Test loss: 0.00266 | Test Accuracy: 0.24054 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.29031 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00177 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00064 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00159 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00025 | Test Accuracy: 0.32042 %\n",
            "Test loss: 0.00064 | Test Accuracy: 0.31053 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00146 | Test Accuracy: 0.25050 %\n",
            "Test loss: 0.00150 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00128 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00048 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.30039 %\n",
            "Test loss: 0.00144 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00086 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00077 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00101 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00134 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00085 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00057 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00103 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00127 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00150 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00084 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00151 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00155 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00110 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00135 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00127 | Test Accuracy: 0.25046 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00100 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00072 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00075 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00079 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.27056 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00130 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00031 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00057 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00079 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00074 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00058 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00058 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00085 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00105 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00119 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00143 | Test Accuracy: 0.25046 %\n",
            "Test loss: 0.00127 | Test Accuracy: 0.25040 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00053 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00039 | Test Accuracy: 0.32032 %\n",
            "Test loss: 0.00130 | Test Accuracy: 0.26061 %\n",
            "Test loss: 0.00057 | Test Accuracy: 0.31034 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00096 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00074 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00058 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00075 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00075 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00068 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00108 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00072 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00156 | Test Accuracy: 0.25043 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.30032 %\n",
            "Test loss: 0.00174 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00214 | Test Accuracy: 0.23046 %\n",
            "Test loss: 0.00086 | Test Accuracy: 0.28029 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00057 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00127 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00160 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00058 | Test Accuracy: 0.31031 %\n",
            "Test loss: 0.00082 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00082 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00121 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00117 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00132 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00165 | Test Accuracy: 0.24042 %\n",
            "Test loss: 0.00075 | Test Accuracy: 0.29030 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00156 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00085 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00165 | Test Accuracy: 0.24054 %\n",
            "Test loss: 0.00055 | Test Accuracy: 0.30029 %\n",
            "Test loss: 0.00047 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00174 | Test Accuracy: 0.27046 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [02:47<01:50, 55.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.00079 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00123 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00147 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00084 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00103 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00106 | Test Accuracy: 0.25050 %\n",
            "Test loss: 0.00073 | Test Accuracy: 0.30032 %\n",
            "Test loss: 0.00074 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00049 | Test Accuracy: 0.31050 %\n",
            "Test loss: 0.00065 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00096 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00162 | Test Accuracy: 0.24054 %\n",
            "Test loss: 0.00068 | Test Accuracy: 0.32026 %\n",
            "Epoch: 3\n",
            "------------\n",
            "Train loss: 0.30489 | Train accuracy: 88.91667%\n",
            "Test loss: 0.00147 | Test Accuracy: 0.27955 %\n",
            "Test loss: 0.00119 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00046 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00132 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00057 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00041 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.25059 %\n",
            "Test loss: 0.00038 | Test Accuracy: 0.31031 %\n",
            "Test loss: 0.00061 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00117 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00087 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00170 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00063 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00139 | Test Accuracy: 0.25059 %\n",
            "Test loss: 0.00123 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.24051 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.30029 %\n",
            "Test loss: 0.00064 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00112 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00213 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00135 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00145 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00121 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00077 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00191 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00123 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00105 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00093 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00056 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00057 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00157 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00082 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00153 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00086 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00198 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00112 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00096 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00064 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00025 | Test Accuracy: 0.31050 %\n",
            "Test loss: 0.00077 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00058 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00058 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00129 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00168 | Test Accuracy: 0.25050 %\n",
            "Test loss: 0.00123 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00045 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00209 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00155 | Test Accuracy: 0.25040 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00106 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00192 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00157 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00086 | Test Accuracy: 0.28038 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.28038 %\n",
            "Test loss: 0.00073 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00048 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00169 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00203 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00174 | Test Accuracy: 0.25043 %\n",
            "Test loss: 0.00161 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00180 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00155 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00110 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00033 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00167 | Test Accuracy: 0.27056 %\n",
            "Test loss: 0.00096 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00192 | Test Accuracy: 0.24051 %\n",
            "Test loss: 0.00172 | Test Accuracy: 0.24039 %\n",
            "Test loss: 0.00123 | Test Accuracy: 0.28032 %\n",
            "Test loss: 0.00134 | Test Accuracy: 0.25050 %\n",
            "Test loss: 0.00053 | Test Accuracy: 0.31031 %\n",
            "Test loss: 0.00061 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00085 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00192 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00187 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00121 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00085 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00039 | Test Accuracy: 0.32042 %\n",
            "Test loss: 0.00112 | Test Accuracy: 0.27059 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00125 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00149 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00123 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00064 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00154 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00100 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00169 | Test Accuracy: 0.25046 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00223 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00051 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00174 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00032 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00043 | Test Accuracy: 0.31050 %\n",
            "Test loss: 0.00054 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00063 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00060 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00049 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00131 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00153 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00063 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00178 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00138 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00086 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00144 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00105 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00190 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00135 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00166 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00100 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00119 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00125 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00108 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00037 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00244 | Test Accuracy: 0.25059 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00212 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00025 | Test Accuracy: 0.32032 %\n",
            "Test loss: 0.00084 | Test Accuracy: 0.30054 %\n",
            "Test loss: 0.00117 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00199 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00300 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00050 | Test Accuracy: 0.31034 %\n",
            "Test loss: 0.00303 | Test Accuracy: 0.23062 %\n",
            "Test loss: 0.00132 | Test Accuracy: 0.28029 %\n",
            "Test loss: 0.00096 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00152 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00053 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00050 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00134 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00028 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00060 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00148 | Test Accuracy: 0.24051 %\n",
            "Test loss: 0.00139 | Test Accuracy: 0.28032 %\n",
            "Test loss: 0.00117 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00085 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00061 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00125 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00079 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00054 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00142 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00112 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00042 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00086 | Test Accuracy: 0.27056 %\n",
            "Test loss: 0.00138 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00162 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00077 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00161 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00121 | Test Accuracy: 0.28038 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00048 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00141 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00055 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00084 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00072 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00106 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00065 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00079 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00082 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00045 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00053 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00010 | Test Accuracy: 0.32042 %\n",
            "Test loss: 0.00063 | Test Accuracy: 0.31053 %\n",
            "Test loss: 0.00063 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00075 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00142 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00077 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00045 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00045 | Test Accuracy: 0.31050 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00138 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00085 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00060 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00140 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00168 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00046 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00150 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00019 | Test Accuracy: 0.32032 %\n",
            "Test loss: 0.00138 | Test Accuracy: 0.27059 %\n",
            "Test loss: 0.00045 | Test Accuracy: 0.30039 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00072 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00075 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00082 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00129 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00131 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00082 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00196 | Test Accuracy: 0.21059 %\n",
            "Test loss: 0.00197 | Test Accuracy: 0.26026 %\n",
            "Test loss: 0.00082 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00061 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00144 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00172 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00032 | Test Accuracy: 0.32038 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.30054 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00147 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00110 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00119 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00079 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00184 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00065 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00168 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00055 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00203 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00065 | Test Accuracy: 0.30032 %\n",
            "Test loss: 0.00159 | Test Accuracy: 0.24058 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [03:41<00:54, 54.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.00148 | Test Accuracy: 0.27034 %\n",
            "Test loss: 0.00073 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00085 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00048 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00061 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00052 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00108 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00055 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00148 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.28042 %\n",
            "Epoch: 4\n",
            "------------\n",
            "Train loss: 0.28981 | Train accuracy: 89.56333%\n",
            "Test loss: 0.00215 | Test Accuracy: 0.26957 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00065 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00030 | Test Accuracy: 0.31050 %\n",
            "Test loss: 0.00118 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00063 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00050 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00040 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00068 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00053 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00085 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00134 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.31050 %\n",
            "Test loss: 0.00129 | Test Accuracy: 0.26058 %\n",
            "Test loss: 0.00128 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00142 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00082 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00038 | Test Accuracy: 0.32045 %\n",
            "Test loss: 0.00112 | Test Accuracy: 0.28058 %\n",
            "Test loss: 0.00129 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00201 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00049 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00145 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00100 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00134 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00077 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00133 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.28039 %\n",
            "Test loss: 0.00101 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00117 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00074 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00142 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00103 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00130 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00031 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00047 | Test Accuracy: 0.31050 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00177 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00095 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00157 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00058 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00058 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00120 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00068 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00182 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00118 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00064 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00025 | Test Accuracy: 0.32045 %\n",
            "Test loss: 0.00052 | Test Accuracy: 0.31053 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00038 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00046 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00117 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00164 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.28039 %\n",
            "Test loss: 0.00061 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00046 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00206 | Test Accuracy: 0.25059 %\n",
            "Test loss: 0.00135 | Test Accuracy: 0.27037 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00185 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00119 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00113 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00061 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00177 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00171 | Test Accuracy: 0.24051 %\n",
            "Test loss: 0.00186 | Test Accuracy: 0.27034 %\n",
            "Test loss: 0.00164 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00157 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00130 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00084 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00055 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00146 | Test Accuracy: 0.25059 %\n",
            "Test loss: 0.00093 | Test Accuracy: 0.30032 %\n",
            "Test loss: 0.00181 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00139 | Test Accuracy: 0.23046 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.28029 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00049 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00191 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00127 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00172 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00139 | Test Accuracy: 0.28038 %\n",
            "Test loss: 0.00068 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00097 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00037 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.27056 %\n",
            "Test loss: 0.00086 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00154 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00154 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00114 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00049 | Test Accuracy: 0.31050 %\n",
            "Test loss: 0.00132 | Test Accuracy: 0.26058 %\n",
            "Test loss: 0.00093 | Test Accuracy: 0.28039 %\n",
            "Test loss: 0.00056 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00147 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00152 | Test Accuracy: 0.25040 %\n",
            "Test loss: 0.00117 | Test Accuracy: 0.28035 %\n",
            "Test loss: 0.00198 | Test Accuracy: 0.23053 %\n",
            "Test loss: 0.00046 | Test Accuracy: 0.29027 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00158 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00064 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00065 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00025 | Test Accuracy: 0.32038 %\n",
            "Test loss: 0.00037 | Test Accuracy: 0.30054 %\n",
            "Test loss: 0.00060 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00072 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00106 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00053 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00072 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00046 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00096 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00166 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00086 | Test Accuracy: 0.27040 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00133 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00139 | Test Accuracy: 0.25046 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00130 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00102 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00112 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00153 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00183 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00078 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00158 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00125 | Test Accuracy: 0.26045 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00040 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00202 | Test Accuracy: 0.26058 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00167 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00026 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00079 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00159 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00304 | Test Accuracy: 0.22054 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.29024 %\n",
            "Test loss: 0.00300 | Test Accuracy: 0.23056 %\n",
            "Test loss: 0.00110 | Test Accuracy: 0.28029 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00092 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00132 | Test Accuracy: 0.26051 %\n",
            "Test loss: 0.00027 | Test Accuracy: 0.31034 %\n",
            "Test loss: 0.00066 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00168 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00093 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00036 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00127 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00087 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00054 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00072 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00108 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00055 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00053 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00103 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00111 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00074 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00163 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00147 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00072 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00173 | Test Accuracy: 0.25053 %\n",
            "Test loss: 0.00128 | Test Accuracy: 0.26039 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.28038 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00094 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00143 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00101 | Test Accuracy: 0.27043 %\n",
            "Test loss: 0.00034 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00065 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00084 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00089 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00075 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00115 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00068 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00079 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00069 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00107 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.29037 %\n",
            "Test loss: 0.00135 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00052 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.31050 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.27056 %\n",
            "Test loss: 0.00055 | Test Accuracy: 0.31037 %\n",
            "Test loss: 0.00056 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00105 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00014 | Test Accuracy: 0.32042 %\n",
            "Test loss: 0.00033 | Test Accuracy: 0.31053 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.31050 %\n",
            "Test loss: 0.00099 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00132 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.30035 %\n",
            "Test loss: 0.00080 | Test Accuracy: 0.28051 %\n",
            "Test loss: 0.00049 | Test Accuracy: 0.31040 %\n",
            "Test loss: 0.00033 | Test Accuracy: 0.32048 %\n",
            "Test loss: 0.00070 | Test Accuracy: 0.30054 %\n",
            "Test loss: 0.00073 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00095 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00076 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00088 | Test Accuracy: 0.28048 %\n",
            "Test loss: 0.00130 | Test Accuracy: 0.26048 %\n",
            "Test loss: 0.00135 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00162 | Test Accuracy: 0.26042 %\n",
            "Test loss: 0.00139 | Test Accuracy: 0.28038 %\n",
            "Test loss: 0.00087 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00057 | Test Accuracy: 0.30042 %\n",
            "Test loss: 0.00158 | Test Accuracy: 0.24058 %\n",
            "Test loss: 0.00027 | Test Accuracy: 0.32026 %\n",
            "Test loss: 0.00161 | Test Accuracy: 0.25062 %\n",
            "Test loss: 0.00032 | Test Accuracy: 0.31031 %\n",
            "Test loss: 0.00116 | Test Accuracy: 0.27056 %\n",
            "Test loss: 0.00095 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.29043 %\n",
            "Test loss: 0.00045 | Test Accuracy: 0.31043 %\n",
            "Test loss: 0.00052 | Test Accuracy: 0.31050 %\n",
            "Test loss: 0.00047 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00062 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00067 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00124 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00091 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.30045 %\n",
            "Test loss: 0.00136 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00138 | Test Accuracy: 0.25046 %\n",
            "Test loss: 0.00061 | Test Accuracy: 0.30032 %\n",
            "Test loss: 0.00145 | Test Accuracy: 0.25056 %\n",
            "Test loss: 0.00193 | Test Accuracy: 0.25040 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.29034 %\n",
            "Test loss: 0.00050 | Test Accuracy: 0.32042 %\n",
            "Test loss: 0.00054 | Test Accuracy: 0.30054 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.27053 %\n",
            "Test loss: 0.00147 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00135 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00032 | Test Accuracy: 0.32035 %\n",
            "Test loss: 0.00061 | Test Accuracy: 0.30054 %\n",
            "Test loss: 0.00090 | Test Accuracy: 0.26054 %\n",
            "Test loss: 0.00169 | Test Accuracy: 0.22048 %\n",
            "Test loss: 0.00074 | Test Accuracy: 0.31021 %\n",
            "Test loss: 0.00104 | Test Accuracy: 0.29053 %\n",
            "Test loss: 0.00126 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00071 | Test Accuracy: 0.28042 %\n",
            "Test loss: 0.00098 | Test Accuracy: 0.28045 %\n",
            "Test loss: 0.00143 | Test Accuracy: 0.27046 %\n",
            "Test loss: 0.00050 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00081 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00151 | Test Accuracy: 0.24058 %\n",
            "Test loss: 0.00082 | Test Accuracy: 0.27034 %\n",
            "Test loss: 0.00046 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00110 | Test Accuracy: 0.29050 %\n",
            "Test loss: 0.00131 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00060 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00109 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00151 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00074 | Test Accuracy: 0.29040 %\n",
            "Test loss: 0.00059 | Test Accuracy: 0.29046 %\n",
            "Test loss: 0.00129 | Test Accuracy: 0.27050 %\n",
            "Test loss: 0.00053 | Test Accuracy: 0.30038 %\n",
            "Test loss: 0.00083 | Test Accuracy: 0.30048 %\n",
            "Test loss: 0.00033 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00035 | Test Accuracy: 0.32048 %\n",
            "Test loss: 0.00029 | Test Accuracy: 0.31053 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [04:36<00:00, 55.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.00071 | Test Accuracy: 0.30051 %\n",
            "Test loss: 0.00049 | Test Accuracy: 0.31046 %\n",
            "Test loss: 0.00143 | Test Accuracy: 0.28054 %\n",
            "Test loss: 0.00187 | Test Accuracy: 0.24051 %\n",
            "Test loss: 0.00075 | Test Accuracy: 0.30029 %\n",
            "Training time: 276.0380973749998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label."
      ],
      "metadata": {
        "id": "w1CsHhPpxp1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(\n",
        "    model: torch.nn.Module,\n",
        "    data: list,\n",
        "    device: torch.device = device):\n",
        "  pred_probs = []\n",
        "  model.eval()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for sample in data:\n",
        "      sample = torch.unsqueeze(sample, dim=0).to(device)\n",
        "\n",
        "      pred_logit = model(sample)\n",
        "\n",
        "      pred_prob = torch.softmax(pred_logit.squeeze(), dim=0)\n",
        "\n",
        "      pred_probs.append(pred_prob.cpu())\n",
        "\n",
        "  return torch.stack(pred_probs)"
      ],
      "metadata": {
        "id": "_YGgZvSobNxu"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take 5 random samples\n",
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "test_samples = []\n",
        "test_labels = []\n",
        "\n",
        "for sample, label in random.sample(list(test_data), k=5):\n",
        "  test_samples.append(sample)\n",
        "  test_labels.append(label)"
      ],
      "metadata": {
        "id": "A8OM8TSKZ32p"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_samples[0].shape"
      ],
      "metadata": {
        "id": "JlAl3fTff-TO",
        "outputId": "17de8206-7939-47e7-e0ac-6c6e915eb5d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make prediction on test samples\n",
        "pred_probs = make_predictions(model=model_2,\n",
        "                              data=test_samples)\n",
        "pred_probs"
      ],
      "metadata": {
        "id": "JNCMAkIca8r2",
        "outputId": "6828ac46-a74f-49f2-dfef-4b36c6463c7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6.8010e-08, 2.0706e-08, 4.1742e-08, 2.4429e-07, 1.8432e-08, 9.9965e-01,\n",
              "         3.7651e-07, 5.5896e-06, 7.8178e-06, 3.3204e-04],\n",
              "        [9.3477e-03, 9.3081e-01, 1.2146e-04, 1.7831e-02, 7.3880e-03, 1.1622e-05,\n",
              "         3.4349e-02, 3.5850e-05, 7.3912e-05, 3.2998e-05],\n",
              "        [4.1737e-06, 1.4108e-08, 1.9413e-06, 1.3117e-07, 7.4271e-07, 2.1486e-05,\n",
              "         9.7333e-07, 9.6709e-01, 9.3385e-05, 3.2784e-02],\n",
              "        [7.2867e-04, 5.0717e-05, 3.9856e-01, 7.3177e-04, 5.9845e-01, 1.0009e-07,\n",
              "         1.4182e-03, 4.6329e-06, 5.3605e-05, 2.1164e-06],\n",
              "        [1.2950e-01, 4.6162e-06, 1.6781e-04, 7.0084e-01, 5.7223e-04, 2.3614e-07,\n",
              "         1.6872e-01, 1.5630e-05, 1.8047e-04, 2.2641e-06]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_classes = pred_probs.argmax(dim=1)\n",
        "pred_classes"
      ],
      "metadata": {
        "id": "yH4ggrlXbXHv",
        "outputId": "b7671664-3a57-4998-d007-b0ed74f92bd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 1, 7, 4, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels, pred_classes"
      ],
      "metadata": {
        "id": "UbuPJRckbha8",
        "outputId": "f316cacd-9e2b-4d95-9193-e415969a0c90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([5, 1, 7, 4, 3], tensor([5, 1, 7, 4, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Plot a confusion matrix comparing your model's predictions to the truth labels."
      ],
      "metadata": {
        "id": "qQwzqlBWxrpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot prediction\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "nrows = 2\n",
        "ncols = 3\n",
        "\n",
        "for i, sample in enumerate(test_samples):\n",
        "  plt.subplot(nrows, ncols, i+1)\n",
        "  plt.imshow(sample.squeeze(), cmap=\"gray\")\n",
        "\n",
        "  pred_label = class_names[pred_classes[i]]\n",
        "\n",
        "  truth_label = class_names[test_labels[i]]\n",
        "\n",
        "  title_text = f\"Pred: {pred_label} | Truth: {truth_label}\"\n",
        "\n",
        "  if pred_label == truth_label:\n",
        "    plt.title(title_text, fontsize=10, c=\"g\")\n",
        "  else:\n",
        "    plt.title(title_text, fontsize=10, c=\"r\")\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "vSrXiT_AbQ6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "bc4de956-337d-47e2-ce57-363d38255d73"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?"
      ],
      "metadata": {
        "id": "lj6bDhoWxt2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn([1, 3, 64, 64])\n",
        "input"
      ],
      "metadata": {
        "id": "leCTsqtSbR5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e990ec24-3096-4b03-ec01-483efd657c29"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-2.3169, -0.2168, -1.3847,  ...,  0.6039, -1.7223, -0.8278],\n",
              "          [-0.4976,  0.4747, -2.5095,  ...,  1.6048, -2.4801, -0.4175],\n",
              "          [-0.1933,  0.6526, -1.9006,  ...,  1.5080,  0.3094, -0.5003],\n",
              "          ...,\n",
              "          [ 1.3945,  1.1369,  1.1797,  ...,  0.3114, -0.5756,  0.3273],\n",
              "          [ 0.5520, -0.7733, -2.4740,  ..., -1.5076, -0.4230, -0.4520],\n",
              "          [-1.5838,  0.8040,  0.4396,  ..., -1.4912,  0.5385,  1.3362]],\n",
              "\n",
              "         [[ 0.3451, -0.1033,  0.4315,  ...,  0.9802, -0.0586,  2.0731],\n",
              "          [-1.8001,  1.4671, -0.1637,  ..., -1.5173,  0.2003, -0.2469],\n",
              "          [ 0.1620,  0.3937, -0.5063,  ...,  0.6884,  1.6444, -0.0973],\n",
              "          ...,\n",
              "          [ 0.8699, -0.7617, -0.5187,  ...,  0.3781, -0.5251,  1.1868],\n",
              "          [-0.9007, -0.5312,  0.0827,  ..., -0.3169, -1.6129, -0.9479],\n",
              "          [-0.0292,  1.7699,  0.7444,  ...,  0.1274,  0.3783,  1.7934]],\n",
              "\n",
              "         [[-0.0848,  1.2047,  0.7305,  ...,  0.4399,  0.6742, -0.5764],\n",
              "          [ 1.7595,  1.9139, -0.3746,  ...,  0.6252, -0.6523, -0.8380],\n",
              "          [-0.2568, -0.6226,  0.5190,  ...,  1.8709, -0.3116,  0.2731],\n",
              "          ...,\n",
              "          [-1.4029, -0.6841, -0.0965,  ..., -0.0161,  0.1193, -0.7611],\n",
              "          [ 1.3910,  0.9389,  0.0155,  ...,  0.5527,  0.0050,  0.5645],\n",
              "          [-1.3799, -0.4843,  0.9146,  ..., -0.6653, -2.2272,  0.2154]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=10, stride=1)"
      ],
      "metadata": {
        "id": "ewuw97Bzd0Na"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = m(input)\n",
        "output.shape\n",
        "output"
      ],
      "metadata": {
        "id": "VQKBJElVeK96",
        "outputId": "e4c7bd2c-4acb-47e2-97ee-4de60a8f0793",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.8343,  0.2159, -0.2763,  ...,  0.0660,  0.3062, -0.0227],\n",
              "          [-0.1125,  0.6037, -0.3642,  ...,  0.2733,  0.2862, -0.6017],\n",
              "          [ 0.2606, -0.7561, -0.8991,  ...,  0.2023, -0.2530,  0.2173],\n",
              "          ...,\n",
              "          [ 0.6015, -0.0839,  0.7101,  ..., -1.1608,  0.9696, -0.8531],\n",
              "          [-1.0790, -0.0962,  0.4749,  ...,  0.1461,  1.2514,  1.1650],\n",
              "          [-1.1696,  0.2275,  0.6774,  ..., -0.1094, -0.6386, -0.2735]],\n",
              "\n",
              "         [[ 0.4587,  1.1530,  0.0773,  ..., -0.0762,  0.5922, -0.7471],\n",
              "          [ 0.1288,  0.7747,  0.2449,  ...,  0.4672, -0.2786, -1.1536],\n",
              "          [ 0.7579,  0.5571,  0.5803,  ..., -0.6714, -0.5804,  0.2090],\n",
              "          ...,\n",
              "          [-0.8777, -0.2194,  0.3578,  ..., -0.6963, -0.0453,  0.2534],\n",
              "          [-0.7817,  0.4457,  0.6199,  ...,  0.0810, -0.0920, -0.2516],\n",
              "          [ 0.0493, -0.4959, -1.3279,  ...,  0.2979, -0.2346, -1.0937]],\n",
              "\n",
              "         [[-0.6399, -0.5582,  0.4670,  ..., -0.0593,  0.2055,  1.0792],\n",
              "          [-0.7946, -0.3009,  0.4670,  ...,  0.3471, -0.0056, -0.2482],\n",
              "          [ 0.1041, -0.1335, -1.0931,  ..., -0.0404, -0.4928,  0.4692],\n",
              "          ...,\n",
              "          [ 1.0567, -0.2730,  0.6975,  ...,  0.6222, -0.1320, -0.0395],\n",
              "          [-0.8408, -0.8856, -0.1655,  ..., -0.2096, -1.0946, -0.1236],\n",
              "          [-0.7288,  1.2226,  1.3054,  ..., -0.1603,  0.5937,  0.0702]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 0.6312,  0.1371, -0.0259,  ..., -0.0263, -0.2358, -0.3983],\n",
              "          [ 0.3451, -0.3706,  0.0453,  ..., -0.5535,  0.9723, -1.0511],\n",
              "          [-1.5825,  0.3623, -0.3062,  ...,  0.6620,  0.5139,  0.0919],\n",
              "          ...,\n",
              "          [-0.7984, -0.7028, -0.0399,  ..., -0.2280, -0.0573, -0.0568],\n",
              "          [-0.3578,  0.9164,  0.8631,  ...,  0.5412, -0.0283,  0.4395],\n",
              "          [-0.2269,  0.1207, -0.7597,  ..., -0.4377,  0.4366, -0.2561]],\n",
              "\n",
              "         [[-0.3042, -0.0275,  0.2452,  ...,  0.6404, -0.1131, -0.7778],\n",
              "          [-0.1844, -0.0763,  0.3717,  ...,  0.1179, -0.8417, -0.9855],\n",
              "          [ 0.9096,  1.5063, -0.1608,  ..., -0.4824, -0.4100, -0.0219],\n",
              "          ...,\n",
              "          [-0.0723,  0.4169, -0.4190,  ..., -0.0328,  0.3720,  0.0789],\n",
              "          [-0.6217,  0.3955, -0.8545,  ...,  0.2500, -0.4116,  0.6388],\n",
              "          [-0.0191, -0.4730, -1.0028,  ..., -0.2549, -0.0806,  0.3109]],\n",
              "\n",
              "         [[-0.1655, -0.3495,  0.1777,  ..., -0.2410,  0.3465,  0.1459],\n",
              "          [-0.4123,  0.2272,  0.0815,  ...,  0.0410,  1.1651,  0.6806],\n",
              "          [ 0.1204,  0.2766,  1.3397,  ...,  1.2261,  0.5881, -0.5255],\n",
              "          ...,\n",
              "          [ 0.4419,  0.2351, -0.4444,  ...,  0.6098, -0.1844, -0.6515],\n",
              "          [ 0.0171,  0.2798,  0.0366,  ..., -0.0632, -1.1122,  0.8508],\n",
              "          [ 0.3749, -1.0824,  0.0047,  ..., -0.4857, -0.1421,  1.1400]]]],\n",
              "       grad_fn=<ConvolutionBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. Use a model similar to the trained `model_2` from notebook 03 to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset.\n",
        "* Then plot some predictions where the model was wrong alongside what the label of the image should've been.\n",
        "* After visualing these predictions do you think it's more of a modelling error or a data error?\n",
        "* As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
      ],
      "metadata": {
        "id": "VHS20cNTxwSi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "78a8LjtdbSZj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}